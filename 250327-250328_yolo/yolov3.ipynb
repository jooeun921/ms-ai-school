{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo를 활용해서 Oject Detection 진행하고, 인식한 Object 박스로 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8083\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8083/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "weights_path = \"yolo3/yolov3.weights\"\n",
    "config_path = \"yolo3/yolov3.cfg\"\n",
    "names_path = \"yolo3/coco_korean.names\"\n",
    "\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "with open(names_path, \"r\", encoding='utf-8') as file:\n",
    "    label_list = file.read().strip().split(\"\\n\")\n",
    "\n",
    "# print(net, label_list)\n",
    "\n",
    "def stream_webcam(image):\n",
    "    return image\n",
    "\n",
    "def detect_objects(image):\n",
    "    drawn_image = Image.fromarray(image.copy())\n",
    "    draw = ImageDraw.Draw(drawn_image)\n",
    "\n",
    "    # image의 width, height를 가져온다.\n",
    "    height, width = image.shape[:2]\n",
    "    # print(height, width)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob=blob)\n",
    "    # 블롭을 생성하고 전방향 전파 진행. \n",
    "    layer_name_list = net.getLayerNames()\n",
    "    output_layer_list = [layer_name_list[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # yolo_82, yolo_94, yolo_102 총 3개의 레이어들이 예측을 진행. detection_list에는 총 3개의 예측이 있음.\n",
    "    detection_list = net.forward(output_layer_list)\n",
    "\n",
    "    for output in detection_list:\n",
    "        # output : 각 레이어의 예측 정보\n",
    "        for detection in output:\n",
    "            # detection : 총 85개. x, y, w, h, confidence + 80개의 names 정보.\n",
    "            score_list = detection[5:]\n",
    "            class_index = np.argmax(score_list)\n",
    "            confidence = score_list[class_index]\n",
    "\n",
    "            if confidence > 0:\n",
    "                # print(class_index, label_list[class_index], confidence)\n",
    "                bounding_box = detection[:4] * np.array([width, height, width, height])\n",
    "                center_x, center_y, w, h = bounding_box.astype('int')\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                # print(x if x > 0 else 0, y if y > 0 else 0, w, h)\n",
    "\n",
    "                draw.rectangle((x, y, x + w, y + h), outline=(0, 255, 0), width=3)\n",
    "                draw.text((x + 5, y+ 5), text=\"Confidence : {:.2f}%\".format(confidence*100), fill=(255, 0, 0))\n",
    "\n",
    "            # if class_index > 0:\n",
    "            #     print(class_index, confidence)\n",
    "\n",
    "            # print(detection[:5])\n",
    "            # print(detection[5:])\n",
    "\n",
    "    return drawn_image\n",
    "    # print(image)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    webcam_input = gr.Image(label=\"카메라\", sources=\"webcam\", streaming=True, width=480, height=270, mirror_webcam=False)\n",
    "    output_image = gr.Image(label=\"검출 화면\", type=\"pil\")\n",
    "\n",
    "    # webcam_input.stream(stream_webcam, inputs=[webcam_input], outputs=[output_image])\n",
    "    webcam_input.stream(detect_objects, inputs=[webcam_input], outputs=[output_image])\n",
    "                        \n",
    "demo.launch(server_port=8083)\n",
    "\n",
    "# image = cv2.imread(\"C:/Users/jooeu/Desktop/git/ms-ai-school/250327_yolo3/test_image_2.jpg\")\n",
    "# detect_objects(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복되어 인식되는 값이 많아서 그 값 중에서 일부만 가져와서 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8083\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8083/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(57), np.int64(57), np.int64(57)] [1 3]\n",
      "사람 637 193 609 590 0.98044986\n",
      "소파 138 339 1697 593 0.5562487\n",
      "[np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [0 6]\n",
      "사람 632 195 624 586 0.9781089\n",
      "TV 모니터 250 343 1644 712 0.77255416\n",
      "[np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [4 7]\n",
      "사람 573 207 695 616 0.9314702\n",
      "TV 모니터 179 250 1637 752 0.8806646\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [1 8]\n",
      "사람 595 197 646 577 0.9619559\n",
      "TV 모니터 273 360 1607 673 0.735822\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(72)] [0 9]\n",
      "사람 661 192 419 592 0.9901688\n",
      "사람 980 226 474 554 0.98761785\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(0), np.int64(0)] [9 1 6]\n",
      "사람 985 224 475 557 0.9946769\n",
      "사람 686 199 449 575 0.97999364\n",
      "TV 모니터 199 139 1513 789 0.59966975\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(0)] [9 0]\n",
      "사람 1006 209 464 590 0.9937358\n",
      "사람 654 186 422 600 0.96359473\n",
      "[np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62)] [11  0 12]\n",
      "사람 998 213 469 582 0.9913749\n",
      "사람 648 183 425 600 0.977291\n",
      "TV 모니터 199 164 1491 912 0.62597275\n",
      "[np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(73)] [4 1]\n",
      "사람 1012 157 432 646 0.96602595\n",
      "사람 545 220 499 531 0.86151487\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [2 3]\n",
      "사람 1090 154 363 617 0.9914194\n",
      "사람 455 259 419 530 0.9674965\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [ 5 14 20]\n",
      "사람 1100 170 398 553 0.98216033\n",
      "사람 549 269 338 486 0.8578386\n",
      "노트북 1297 572 261 192 0.6499584\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62)] [2 3]\n",
      "사람 551 188 777 593 0.9982771\n",
      "TV 모니터 232 67 1483 781 0.7843811\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62)] [2 8]\n",
      "사람 543 189 802 589 0.9972466\n",
      "TV 모니터 191 72 1575 910 0.6640243\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(62)] [2 8]\n",
      "사람 532 188 815 594 0.99707276\n",
      "TV 모니터 198 74 1564 909 0.7377567\n",
      "[np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [1 6]\n",
      "사람 540 196 777 583 0.9982065\n",
      "TV 모니터 189 95 1586 871 0.67134625\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(63), np.int64(76)] [0]\n",
      "사람 716 176 527 608 0.9884826\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [0 7]\n",
      "사람 706 150 572 628 0.9802518\n",
      "TV 모니터 312 330 1325 754 0.5592142\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(62), np.int64(62), np.int64(62)] [0 6]\n",
      "사람 721 142 531 639 0.97782433\n",
      "TV 모니터 275 346 1387 717 0.6560244\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(62)] [0 8]\n",
      "사람 722 145 543 631 0.98224026\n",
      "TV 모니터 310 341 1331 731 0.6179128\n",
      "[np.int64(0), np.int64(62), np.int64(0), np.int64(0), np.int64(62)] [0]\n",
      "사람 704 181 543 587 0.98946947\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[np.int64(63), np.int64(63)] ()\n",
      "[np.int64(63), np.int64(63)] [1]\n",
      "노트북 240 37 1676 959 0.53869385\n",
      "[np.int64(63), np.int64(63)] ()\n",
      "[np.int64(63), np.int64(63)] ()\n",
      "[np.int64(63), np.int64(63)] ()\n",
      "[np.int64(63), np.int64(63), np.int64(63)] ()\n",
      "[np.int64(63), np.int64(63)] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[np.int64(62), np.int64(72)] ()\n",
      "[np.int64(73), np.int64(72), np.int64(72)] [2]\n",
      "냉장고 228 0 1682 1107 0.77781427\n",
      "[np.int64(73), np.int64(72), np.int64(72), np.int64(0)] [2]\n",
      "냉장고 218 0 1700 1113 0.7376907\n",
      "[np.int64(73), np.int64(72), np.int64(72)] [2]\n",
      "냉장고 214 0 1706 1117 0.72148424\n",
      "[np.int64(72), np.int64(72)] [1]\n",
      "냉장고 155 0 1804 1061 0.6736137\n",
      "[np.int64(73), np.int64(73), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [4 8 7]\n",
      "사람 1427 559 126 165 0.6984203\n",
      "사람 1223 602 29 105 0.5881992\n",
      "사람 1182 601 34 105 0.50299734\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(73), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 6 10  8]\n",
      "사람 1427 559 126 166 0.5976201\n",
      "사람 1224 602 28 105 0.54950625\n",
      "사람 900 344 73 115 0.52473605\n",
      "[np.int64(63), np.int64(63), np.int64(73), np.int64(73), np.int64(73), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 6 10]\n",
      "사람 1427 558 126 166 0.58481723\n",
      "사람 1223 602 29 106 0.5129616\n",
      "[np.int64(62), np.int64(73), np.int64(63), np.int64(73), np.int64(73), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [7 8]\n",
      "사람 1428 505 119 170 0.7226611\n",
      "사람 738 792 109 124 0.51572466\n",
      "[np.int64(63), np.int64(63), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(73), np.int64(0), np.int64(14), np.int64(0), np.int64(0), np.int64(0)] [7]\n",
      "사람 738 769 104 129 0.50130427\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [2 7]\n",
      "사람 829 725 135 170 0.8913168\n",
      "사람 631 770 30 109 0.5185351\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8484243\n",
      "사람 1790 830 49 118 0.7822673\n",
      "사람 631 770 30 109 0.53383607\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(63), np.int64(0), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [ 2 13  7]\n",
      "사람 829 726 135 170 0.8489536\n",
      "사람 1790 830 49 118 0.78226626\n",
      "사람 631 770 30 109 0.53637606\n",
      "[np.int64(73), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] [2 3 4]\n",
      "사람 831 599 130 175 0.7736935\n",
      "사람 822 890 106 124 0.61635494\n",
      "사람 1194 862 82 157 0.5435461\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(14), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0), np.int64(0)] [ 7 22  9  3]\n",
      "사람 820 530 106 134 0.9322508\n",
      "사람 1077 771 75 108 0.68383086\n",
      "사람 1195 504 82 161 0.645613\n",
      "사람 836 252 119 168 0.59510934\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(73), np.int64(0), np.int64(0), np.int64(16), np.int64(16), np.int64(0), np.int64(0)] [0 9]\n",
      "사람 821 261 107 126 0.8927249\n",
      "개 823 522 59 102 0.68622255\n",
      "[np.int64(0), np.int64(73), np.int64(0), np.int64(16), np.int64(16), np.int64(0), np.int64(0)] ()\n",
      "[np.int64(0), np.int64(73), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0)] ()\n",
      "[np.int64(0), np.int64(73), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0)] ()\n",
      "[np.int64(0), np.int64(73), np.int64(0), np.int64(0), np.int64(16), np.int64(0), np.int64(0)] ()\n",
      "[np.int64(73), np.int64(16), np.int64(16), np.int64(0), np.int64(14)] ()\n",
      "[np.int64(0), np.int64(0), np.int64(14), np.int64(14), np.int64(0), np.int64(0), np.int64(0)] [4 2]\n",
      "사람 609 706 56 106 0.80913615\n",
      "새 620 208 138 58 0.6021627\n",
      "[np.int64(14)] ()\n",
      "[np.int64(14), np.int64(14)] ()\n",
      "[np.int64(72), np.int64(72)] [1]\n",
      "냉장고 198 0 1748 1088 0.8866806\n",
      "[np.int64(72), np.int64(72)] [1]\n",
      "냉장고 198 0 1748 1088 0.8866806\n",
      "[np.int64(72), np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(72)] [3]\n",
      "냉장고 79 0 1578 1124 0.801566\n",
      "[np.int64(72), np.int64(72), np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [5]\n",
      "냉장고 73 71 1846 1057 0.8079363\n",
      "[np.int64(72), np.int64(72), np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(72)] [5]\n",
      "냉장고 85 60 1824 1078 0.73914224\n",
      "[np.int64(72), np.int64(72), np.int64(63), np.int64(72), np.int64(72), np.int64(72)] [4]\n",
      "냉장고 90 67 1814 1066 0.66816366\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 168 0 1787 1138 0.675055\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 168 0 1787 1138 0.675055\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1138 0.6709201\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.6717173\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.6717173\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.6717173\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.6717173\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(72)] [4]\n",
      "노트북 167 0 1789 1137 0.67183644\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [6]\n",
      "냉장고 211 106 1706 971 0.8049123\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [1]\n",
      "냉장고 87 11 1796 1092 0.9508062\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [5]\n",
      "냉장고 91 88 1778 1007 0.9844856\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [5]\n",
      "냉장고 88 77 1795 1027 0.98009735\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [6]\n",
      "냉장고 90 74 1792 1033 0.97796786\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [2 7]\n",
      "냉장고 146 0 1825 1095 0.8985183\n",
      "사람 280 210 56 145 0.79751766\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [2 7]\n",
      "냉장고 146 0 1825 1094 0.89752\n",
      "사람 280 210 56 145 0.78552055\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [2 7]\n",
      "냉장고 146 0 1825 1094 0.89752\n",
      "사람 280 210 56 145 0.78552055\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [2 7]\n",
      "냉장고 146 0 1825 1094 0.89752\n",
      "사람 280 210 56 145 0.78552055\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0)] [2]\n",
      "냉장고 156 0 1807 1092 0.9140633\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [6]\n",
      "냉장고 91 73 1792 1034 0.9783097\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [6]\n",
      "냉장고 90 73 1793 1034 0.9788141\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [6]\n",
      "냉장고 91 73 1792 1034 0.9783097\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(0), np.int64(0)] [2 7]\n",
      "냉장고 157 0 1806 1092 0.91425174\n",
      "사람 280 208 56 147 0.69994277\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[np.int64(62), np.int64(62)] ()\n",
      "[np.int64(62), np.int64(62)] ()\n",
      "[np.int64(62), np.int64(62), np.int64(62)] ()\n",
      "[np.int64(62), np.int64(62)] ()\n",
      "[np.int64(62), np.int64(62), np.int64(62)] ()\n",
      "[np.int64(62), np.int64(62)] ()\n",
      "[] ()\n",
      "[np.int64(74)] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[] ()\n",
      "[np.int64(72)] ()\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 158 67 1654 951 0.5062789\n",
      "[np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 171 53 1791 974 0.5226838\n",
      "[np.int64(72), np.int64(62), np.int64(25), np.int64(25)] [2]\n",
      "우산 486 392 315 278 0.64320254\n",
      "[np.int64(72), np.int64(62), np.int64(25), np.int64(25)] [2]\n",
      "우산 486 392 315 278 0.646501\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 202 19 1724 1007 0.7123073\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 202 19 1724 1007 0.7121138\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 202 20 1724 1006 0.7116677\n",
      "[np.int64(72), np.int64(72), np.int64(72), np.int64(72), np.int64(72)] [2]\n",
      "냉장고 216 41 1746 971 0.8370694\n",
      "[np.int64(63), np.int64(63), np.int64(72), np.int64(72), np.int64(63), np.int64(63)] [3]\n",
      "냉장고 480 10 1503 1044 0.51025844\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [2]\n",
      "TV 모니터 170 58 1794 976 0.6042807\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [2]\n",
      "TV 모니터 171 57 1791 971 0.5924699\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 157 66 1653 952 0.5234298\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 157 66 1653 952 0.5234298\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 150 65 1667 956 0.5317333\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 151 67 1665 954 0.5401694\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 155 65 1658 956 0.51943696\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 150 69 1670 954 0.54508644\n",
      "[np.int64(62), np.int64(62), np.int64(62), np.int64(25)] [1]\n",
      "TV 모니터 155 68 1662 952 0.51079476\n",
      "[np.int64(62), np.int64(63), np.int64(62), np.int64(63)] ()\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67), np.int64(67), np.int64(67), np.int64(67)] [3 2 5 6]\n",
      "휴대폰 725 440 136 239 0.7780709\n",
      "휴대폰 529 447 130 231 0.7512226\n",
      "휴대폰 878 449 119 234 0.67102855\n",
      "휴대폰 1076 448 129 229 0.5007061\n",
      "[np.int64(67), np.int64(67), np.int64(67), np.int64(67), np.int64(67)] [1 2 4 3]\n",
      "휴대폰 525 349 135 233 0.705414\n",
      "휴대폰 724 351 138 233 0.6811547\n",
      "휴대폰 1076 359 127 221 0.553891\n",
      "휴대폰 873 348 129 237 0.54991764\n",
      "[np.int64(67), np.int64(67), np.int64(67), np.int64(67), np.int64(67)] [2 1 3]\n",
      "휴대폰 722 348 138 238 0.81925046\n",
      "휴대폰 526 347 134 234 0.7638988\n",
      "휴대폰 872 348 130 235 0.62295175\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(67)] ()\n",
      "[np.int64(68), np.int64(67), np.int64(67)] ()\n",
      "[np.int64(68), np.int64(67), np.int64(67)] ()\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67)] [3]\n",
      "휴대폰 731 389 128 242 0.5473383\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67)] [3]\n",
      "휴대폰 731 389 128 242 0.5473383\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67)] [3]\n",
      "휴대폰 731 389 128 242 0.53503793\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67)] [3]\n",
      "휴대폰 731 389 128 242 0.53503793\n",
      "[np.int64(68), np.int64(67), np.int64(67), np.int64(67)] [3]\n",
      "휴대폰 731 389 128 242 0.53503793\n",
      "[np.int64(63), np.int64(72), np.int64(72), np.int64(67), np.int64(67), np.int64(67), np.int64(67), np.int64(67)] [4 7]\n",
      "휴대폰 532 107 126 229 0.5483022\n",
      "휴대폰 1076 113 127 217 0.50937915\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 103 48 1782 974 0.71397746\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 118 46 1749 978 0.7219348\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 118 46 1749 978 0.7219348\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 118 46 1749 978 0.7219348\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 120 47 1745 978 0.7174557\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 120 47 1745 978 0.7174557\n",
      "[np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63), np.int64(63)] [3]\n",
      "노트북 120 47 1745 978 0.7174557\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import platform\n",
    " \n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "weights_path = \"yolo3/yolov3.weights\"\n",
    "config_path = \"yolo3/yolov3.cfg\"\n",
    "names_path = \"yolo3/coco_korean.names\"\n",
    "\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "with open(names_path, \"r\", encoding='utf-8') as file:\n",
    "    label_list = file.read().strip().split(\"\\n\")\n",
    "\n",
    "# print(net, label_list)\n",
    "\n",
    "def stream_webcam(image):\n",
    "    return image\n",
    "\n",
    "def random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "def get_font():\n",
    "    font_size = 20\n",
    "    if platform.system() == \"Darwin\":\n",
    "        font = ImageFont.truetype(\"AppleGothic.ttf\", size=font_size)\n",
    "    elif platform.system() == \"Windows\":\n",
    "        font = ImageFont.truetype(\"malgun.ttf\", size=font_size)\n",
    "    else:\n",
    "        font = ImageFont.load_default(size=font_size)\n",
    "    return font\n",
    "\n",
    "def detect_objects(image):\n",
    "    drawn_image = Image.fromarray(image.copy())\n",
    "    draw = ImageDraw.Draw(drawn_image)\n",
    "\n",
    "    # image의 width, height를 가져온다.\n",
    "    height, width = image.shape[:2]\n",
    "    # print(height, width)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob=blob)\n",
    "    # 블롭을 생성하고 전방향 전파 진행. \n",
    "    layer_name_list = net.getLayerNames()\n",
    "    output_layer_list = [layer_name_list[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # yolo_82, yolo_94, yolo_102 총 3개의 레이어들이 예측을 진행. detection_list에는 총 3개의 예측이 있음.\n",
    "    detection_list = net.forward(output_layer_list)\n",
    "\n",
    "    bounding_box_list = []\n",
    "    confidence_list = []\n",
    "    class_index_list = []\n",
    "\n",
    "    for output in detection_list:\n",
    "        # output : 각 레이어의 예측 정보\n",
    "        for detection in output:\n",
    "            # detection : 총 85개. x, y, w, h, confidence + 80개의 names 정보.\n",
    "            score_list = detection[5:]\n",
    "            class_index = np.argmax(score_list)\n",
    "            confidence = score_list[class_index]\n",
    "\n",
    "            if confidence > 0:\n",
    "                # print(class_index, label_list[class_index], confidence)\n",
    "                bounding_box = detection[:4] * np.array([width, height, width, height])\n",
    "                center_x, center_y, w, h = bounding_box.astype('int')\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                if x < 0:\n",
    "                    x = 0\n",
    "                if y < 0:\n",
    "                    y = 0\n",
    "                # print(x, y, w, h)\n",
    "\n",
    "                bounding_box_list.append([x, y, w, h])\n",
    "                confidence_list.append(confidence)\n",
    "                class_index_list.append(class_index)\n",
    "    # NMS (Non-Maximum Suppression) : 중복된 박스 제거. 0.5 이상인 박스들 중에서 가장 높은 confidence를 가진 박스만 남기고 나머지 박스들은 제거. 0.4는 threshold.\n",
    "    extracted_index_list = cv2.dnn.NMSBoxes(bounding_box_list, confidence_list, 0.5, 0.4)\n",
    "    print(class_index_list, extracted_index_list)\n",
    "\n",
    "    for extracted_index in extracted_index_list:\n",
    "\n",
    "        x, y, w, h = bounding_box_list[extracted_index]\n",
    "        confidence = confidence_list[extracted_index]\n",
    "        class_index = class_index_list[extracted_index]\n",
    "        label = label_list[class_index]\n",
    "\n",
    "        color = random_color()\n",
    "        print(label, x, y, w, h, confidence)\n",
    "\n",
    "        draw.rectangle((x, y, x + w, y + h), outline=color, width=3)\n",
    "        draw.text((x + 5, y+ 5), text=\"{} : {:.2f}%\".format(label_list[class_index], confidence*100), fill=color, font=get_font())\n",
    "    return drawn_image\n",
    "    # print(image)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    webcam_input = gr.Image(label=\"카메라\", sources=\"webcam\", streaming=True, width=480, height=270, mirror_webcam=False)\n",
    "    output_image = gr.Image(label=\"검출 화면\", type=\"pil\")\n",
    "\n",
    "    webcam_input.stream(detect_objects, inputs=[webcam_input], outputs=[output_image])\n",
    "                        \n",
    "demo.launch(server_port=8083)\n",
    "\n",
    "# image = cv2.imread(\"C:/Users/jooeu/Desktop/git/ms-ai-school/250327_yolo3/test_image_2.png\")\n",
    "# detect_objects(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT와 음성 받아와서 gradio 인터페이스 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8062\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8062/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 감지된 물체 고양이  \n",
      "    감지 확률 93.46%  \n",
      "    설명 갈색 털을 가진 귀여운 고양이가 바닥에 앉아 있는 모습입니다.  \n",
      "\n",
      "2. 감지된 물체 고양이  \n",
      "    감지 확률 94.95%  \n",
      "    설명 흰 털과 갈색 털을 가진 고양이가 바깥쪽을 바라보고 있는 모습입니다.  \n",
      "\n",
      "3. 감지된 물체 고양이  \n",
      "    감지 확률 95.30%  \n",
      "    설명 작은 크기의 새끼 고양이가 바닥 위에 앉아 있는 모습입니다.  \n",
      "\n",
      "4. 감지된 물체 고양이  \n",
      "    감지 확률 97.00%  \n",
      "    설명 어린 새끼 고양이가 풀밭에 앉아 있는 모습입니다.  \n",
      "\n",
      "5. 감지된 물체 고양이  \n",
      "    감지 확률 81.97%  \n",
      "    설명 회색 줄무늬를 가진 고양이가 뒷발로 서 있는 모습입니다.  \n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import platform\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    " \n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_ENDPOINT = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DEPLOYMENT_NAME = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "SPEECH_ENDPOINT = os.getenv(\"SPEECH_ENDPOINT\")\n",
    "SPEECH_API_KEY = os.getenv(\"SPEECH_API_KEY\")\n",
    "\n",
    "weights_path = \"yolo3/yolov3.weights\"\n",
    "config_path = \"yolo3/yolov3.cfg\"\n",
    "names_path = \"yolo3/coco_korean.names\"\n",
    "\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "with open(names_path, \"r\", encoding='utf-8') as file:\n",
    "    label_list = file.read().strip().split(\"\\n\")\n",
    "\n",
    "# print(net, label_list)\n",
    "\n",
    "def request_gpt(image_array):\n",
    "    endpoint = \"{}/openai/deployments/{}/chat/completions?api-version=2025-01-01-preview\".format(OPENAI_ENDPOINT, DEPLOYMENT_NAME)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": OPENAI_API_KEY\n",
    "    }\n",
    "\n",
    "    # numpy 형태의 이미지를 PIL 형태로 변환\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # PIL를 바이너리 형태로 읽음. buffered_io = io.BytesIO()\n",
    "    buffered_io = io.BytesIO()\n",
    "    image.save(buffered_io, format=\"png\")\n",
    "\n",
    "    # image Base64로 인코딩 utf-8\n",
    "    base64_image = base64.b64encode(buffered_io.getvalue()).decode(\"utf-8\")\n",
    "    # print(base64_image)\n",
    "\n",
    "    message_list = []\n",
    "\n",
    "    # 시스템 메세지 설정\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"\n",
    "                너는 사진 속에서 감지된 물체를 분석하는 봇이야.\n",
    "                무조건 분석결과를 한국어로 답변해줘.\n",
    "                \"\"\"\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"\n",
    "                너는 물체를 감지하는 YOLO 모델이야.\n",
    "                이 사진에서 감지된 물체에 대해 감지확률과 함께 자세한 설명을 붙여줘.\n",
    "                반드시 감지된 물체, 바운딩 박스 안에 있는 물체에 대해서만 설명해줘.\n",
    "                부연 설명 필요없고 감지된 물체에 대해서만 설명해줘.\n",
    "                \"\"\"\n",
    "        }, {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"data:image/png;base64,{}\".format(base64_image),\n",
    "                \"caption\": \"물체 감지 결과\"\n",
    "            }\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    body = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 16000,\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, json=body)\n",
    "    # print(response.status_code, response.text)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        content = response.text\n",
    "\n",
    "    return content\n",
    "\n",
    "def request_tts(text):\n",
    "    endpoint = SPEECH_ENDPOINT\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": SPEECH_API_KEY,\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "        \"X-Microsoft-OutputFormat\": \"riff-44100hz-16bit-mono-pcm\"\n",
    "    }\n",
    "    \n",
    "    body = f\"\"\"\n",
    "        <speak version='1.0' xml:lang='ko-KR'>\n",
    "            <voice name='ko-KR-JiMinNeural'>\n",
    "                <prosody rate=\"20%\">\n",
    "                    {text}\n",
    "                </prosody>\n",
    "            </voice>\n",
    "        </speak>\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=body)\n",
    "    if response.status_code == 200:\n",
    "        file_name = \"response_audio.wav\"\n",
    "        with open(file_name, \"wb\") as audio_file:\n",
    "            audio_file.write(response.content)\n",
    "        return file_name\n",
    "    else:\n",
    "        print(f\"TTS 요청 실패: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def stream_webcam(image):\n",
    "    return image\n",
    "\n",
    "def random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "def get_font():\n",
    "    font_size = 20\n",
    "    if platform.system() == \"Darwin\":\n",
    "        font = ImageFont.truetype(\"AppleGothic.ttf\", size=font_size)\n",
    "    elif platform.system() == \"Windows\":\n",
    "        font = ImageFont.truetype(\"malgun.ttf\", size=font_size)\n",
    "    else:\n",
    "        font = ImageFont.load_default(size=font_size)\n",
    "    return font\n",
    "\n",
    "def detect_objects(image):\n",
    "    drawn_image = Image.fromarray(image.copy())\n",
    "    draw = ImageDraw.Draw(drawn_image)\n",
    "\n",
    "    # image의 width, height를 가져온다.\n",
    "    height, width = image.shape[:2]\n",
    "    # print(height, width)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob=blob)\n",
    "    # 블롭을 생성하고 전방향 전파 진행. \n",
    "    layer_name_list = net.getLayerNames()\n",
    "    output_layer_list = [layer_name_list[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # yolo_82, yolo_94, yolo_102 총 3개의 레이어들이 예측을 진행. detection_list에는 총 3개의 예측이 있음.\n",
    "    detection_list = net.forward(output_layer_list)\n",
    "\n",
    "    bounding_box_list = []\n",
    "    confidence_list = []\n",
    "    class_index_list = []\n",
    "\n",
    "    for output in detection_list:\n",
    "        # output : 각 레이어의 예측 정보\n",
    "        for detection in output:\n",
    "            # detection : 총 85개. x, y, w, h, confidence + 80개의 names 정보.\n",
    "            score_list = detection[5:]\n",
    "            class_index = np.argmax(score_list)\n",
    "            confidence = score_list[class_index]\n",
    "\n",
    "            if confidence > 0:\n",
    "                # print(class_index, label_list[class_index], confidence)\n",
    "                bounding_box = detection[:4] * np.array([width, height, width, height])\n",
    "                center_x, center_y, w, h = bounding_box.astype('int')\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                if x < 0:\n",
    "                    x = 0\n",
    "                if y < 0:\n",
    "                    y = 0\n",
    "                # print(x, y, w, h)\n",
    "\n",
    "                bounding_box_list.append([x, y, w, h])\n",
    "                confidence_list.append(confidence)\n",
    "                class_index_list.append(class_index)\n",
    "    # NMS (Non-Maximum Suppression) : 중복된 박스 제거. 0.5 이상인 박스들 중에서 가장 높은 confidence를 가진 박스만 남기고 나머지 박스들은 제거. 0.4는 threshold.\n",
    "    extracted_index_list = cv2.dnn.NMSBoxes(bounding_box_list, confidence_list, 0.5, 0.4)\n",
    "    # print(class_index_list, extracted_index_list)\n",
    "\n",
    "    for extracted_index in extracted_index_list:\n",
    "\n",
    "        x, y, w, h = bounding_box_list[extracted_index]\n",
    "        confidence = confidence_list[extracted_index]\n",
    "        class_index = class_index_list[extracted_index]\n",
    "        label = label_list[class_index]\n",
    "\n",
    "        color = random_color()\n",
    "        # print(label, x, y, w, h, confidence)\n",
    "\n",
    "        draw.rectangle((x, y, x + w, y + h), outline=color, width=3)\n",
    "        draw.text((x + 5, y+ 5), text=\"{} : {:.2f}%\".format(label_list[class_index], confidence*100), fill=color, font=get_font())\n",
    "    return drawn_image\n",
    "\n",
    "def stream_webcam(image):\n",
    "    drawn_image = detect_objects(image)\n",
    "    return drawn_image\n",
    "\n",
    "def click_capture(image):\n",
    "    return image\n",
    "\n",
    "def click_send_gpt(image_array, histories):\n",
    "    content = request_gpt(image_array)\n",
    "    histories.append({\"role\": \"user\", \"content\": gr.Image(label=\"감지화면\", value=image_array)})\n",
    "    histories.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "    return histories\n",
    "\n",
    "def change_chatbot(histories):\n",
    "    content = histories[-1]['content']\n",
    "    # print(content)\n",
    "    \n",
    "    pattern = r'[^가-힣a-zA-Z\\s%,\\.\\d]'\n",
    "    # pattern = r'[^\\w\\sㄱ-ㅎ가-힣]'\n",
    "\n",
    "    cleaned_content = re.sub(pattern, '', content)\n",
    "    print(cleaned_content)\n",
    "    file_name = request_tts(cleaned_content)  # 음성 변환\n",
    "    return file_name\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        webcam_input = gr.Image(label=\"카메라\", sources=\"webcam\", streaming=True, width=480, height=270, mirror_webcam=False)\n",
    "        output_image = gr.Image(label=\"검출 화면\", type=\"pil\", interactive=False)\n",
    "        output_capture_image = gr.Image(label=\"캡쳐 화면\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        capture_button = gr.Button(\"캡쳐\")\n",
    "        send_gpt_button = gr.Button(\"GPT로 전송\")\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"분석결과\", type=\"messages\")    \n",
    "        chatbot_audio = gr.Audio(label=\"GPT\", interactive=False, autoplay=True)\n",
    "\n",
    "    webcam_input.stream(stream_webcam, inputs=[webcam_input], outputs=[output_image])\n",
    "    capture_button.click(click_capture, inputs=[output_image], outputs=[output_capture_image])\n",
    "    send_gpt_button.click(click_send_gpt, inputs=[output_capture_image, chatbot], outputs=[chatbot])\n",
    "    chatbot.change(change_chatbot, inputs=[chatbot], outputs=[chatbot_audio])\n",
    "                        \n",
    "demo.launch(server_port=8062)\n",
    "\n",
    "# image = cv2.imread(\"C:/Users/jooeu/Desktop/git/ms-ai-school/250327_yolo3/test_image_2.png\")\n",
    "# requst_gpt(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
