{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5483d94f3e8ae33",
   "metadata": {},
   "source": [
    "## Custom Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0843ce2e1ce1d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "training_endpoint = os.getenv(\"TRAINING_ENDPOINT\")\n",
    "prediction_endpoint = os.getenv(\"PREDICTION_ENDPOINT\")\n",
    "\n",
    "training_api_key = os.getenv(\"TRAINING_API_KEY\")\n",
    "prediction_api_key = os.getenv(\"PREDICTION_API_KEY\")\n",
    "\n",
    "prediction_resource_id = os.getenv(\"PREDICTION_RESOURCE_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ad9495ff1e4e5",
   "metadata": {},
   "source": [
    "### Trainer, Predictor 객체화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a045a61081c9476c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:49:59.202348Z",
     "start_time": "2025-03-26T02:49:58.919869Z"
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient # type: ignore\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient # type: ignore\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region, ExportPlatform # type: ignore\n",
    "from msrest.authentication import ApiKeyCredentials # type: ignore\n",
    "import os, time, uuid\n",
    "\n",
    "training_credontials = ApiKeyCredentials(in_headers={\"Training-key\": training_api_key})\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_api_key})\n",
    "\n",
    "trainer = CustomVisionTrainingClient(endpoint=training_endpoint, credentials=training_credontials)\n",
    "predictor = CustomVisionPredictionClient(endpoint=prediction_endpoint, credentials=prediction_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671f8559e017e3",
   "metadata": {},
   "source": [
    "### 프로젝트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7813db10f19e6931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:50:00.531236Z",
     "start_time": "2025-03-26T02:49:59.289842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT :  99e922e4-ce8e-47ef-b9f7-53b28b9471c8 6b021-kitchen-compact\n",
      "DOMAIN :  2e37d7fb-3a54-486a-b4d6-cfc369af0018 General [A2]\n",
      "DOMAIN :  a8e3c40f-fb4a-466f-832a-5e457ae4a344 General [A1]\n",
      "DOMAIN :  ee85a74c-405e-4adc-bb47-ffa8ca0c9f31 General\n",
      "DOMAIN :  c151d5b5-dd07-472a-acc8-15d29dea8518 Food\n",
      "DOMAIN :  ca455789-012d-4b50-9fec-5bb63841c793 Landmarks\n",
      "DOMAIN :  b30a91ae-e3c1-4f73-a81e-c270bff27c39 Retail\n",
      "DOMAIN :  45badf75-3591-4f26-a705-45678d3e9f5f Adult\n",
      "DOMAIN :  a1db07ca-a19a-4830-bae8-e004a42dc863 General (compact) [S1]\n",
      "DOMAIN :  0732100f-1a38-4e49-a514-c9b44c697ab5 General (compact)\n",
      "DOMAIN :  8882951b-82cd-4c32-970b-d5f8cb8bf6d7 Food (compact)\n",
      "DOMAIN :  b5cfd229-2ac7-4b2b-8d0a-2b0661344894 Landmarks (compact)\n",
      "DOMAIN :  6b4faeda-8396-481b-9f8b-177b9fa3097f Retail (compact)\n",
      "DOMAIN :  9c616dff-2e7d-ea11-af59-1866da359ce6 General [A1]\n",
      "DOMAIN :  da2e3a8a-40a5-4171-82f4-58522f70fbc1 General\n",
      "DOMAIN :  1d8ffafe-ec40-4fb2-8f90-72b3b6cecea4 Logo\n",
      "DOMAIN :  3780a898-81c3-4516-81ae-3a139614e1f3 Products on Shelves\n",
      "DOMAIN :  7ec2ac80-887b-48a6-8df9-8b1357765430 General (compact) [S1]\n",
      "DOMAIN :  a27d5ca5-bb19-49d8-a70a-fec086c47f5b General (compact)\n"
     ]
    }
   ],
   "source": [
    "for project in trainer.get_projects():\n",
    "    print(\"PROJECT : \", project.id, project.name)\n",
    "\n",
    "for domain in trainer.get_domains():\n",
    "    print(\"DOMAIN : \", domain.id, domain.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0e080a3957d1a",
   "metadata": {},
   "source": [
    "### 프로젝트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607a7cc730dbcd90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:50:01.307539Z",
     "start_time": "2025-03-26T02:50:00.564392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로젝트 들고 왔어!\n",
      "99e922e4-ce8e-47ef-b9f7-53b28b9471c8 6b021-kitchen-compact\n"
     ]
    }
   ],
   "source": [
    "project_name = \"6b021-kitchen-compact\"\n",
    "project_description = \"포크와 가위를 감지하는 모델\"\n",
    "domain_id = None\n",
    "project_id = None\n",
    "\n",
    "# 기존 프로젝트가 있는지 체크.\n",
    "for project in trainer.get_projects():\n",
    "    if project.name == project_name:\n",
    "        # 기존의 프로젝트가 이미 존재하고 있기 때문에, 프로젝트 아이디를 들고온다.\n",
    "        project_id = project.id\n",
    "        break\n",
    "\n",
    "# 모든 도메인 정보를 체크하고, 만약, 내가 원하는 도메인 정보와 일치 할 경우, 도메인 아이디를 들고 온다.\n",
    "for domain in trainer.get_domains():\n",
    "    if domain.type == \"ObjectDetection\" and domain.name == \"General (compact)\":\n",
    "        domain_id = domain.id\n",
    "        break\n",
    "\n",
    "if domain_id:\n",
    "    # 프로젝트를 만들거나, 프로젝트를 들고 오면 됩니다.\n",
    "    if project_id:\n",
    "        # 이미 존재하는 경우, 프로젝트를 들고 온다.\n",
    "        print(\"프로젝트 들고 왔어!\")\n",
    "        project = trainer.get_project(project_id=project_id)\n",
    "    else:\n",
    "        # 없는 경우에 프로젝트를 생성한다.\n",
    "        print(\"프로젝트 만들었어!\")\n",
    "        project = trainer.create_project(project_name, project_description, domain_id)\n",
    "print(project_id, project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f856bec415086e8",
   "metadata": {},
   "source": [
    "### 태그 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc6480019da1d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:50:01.586993Z",
     "start_time": "2025-03-26T02:50:01.328324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag object at 0x000002497E8A51F0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.Tag object at 0x000002497E8A4440>]\n",
      "scissors 들고 왔어\n",
      "fork 들고 왔어\n",
      "34bc7247-7d2f-4b95-a358-f93223f27ca7 fork\n",
      "c0a3a421-4d36-431c-948f-8e5a0ccce9c0 scissors\n"
     ]
    }
   ],
   "source": [
    "exist_tag_list = trainer.get_tags(project_id)\n",
    "print(exist_tag_list)\n",
    "\n",
    "fork_tag = None\n",
    "scissors_tag = None\n",
    "\n",
    "for tag in exist_tag_list:\n",
    "    if tag.name == \"fork\":\n",
    "        print(\"fork 들고 왔어\")\n",
    "        fork_tag = tag\n",
    "    elif tag.name == \"scissors\":\n",
    "        print(\"scissors 들고 왔어\")\n",
    "        scissors_tag = tag\n",
    "\n",
    "if fork_tag is None:\n",
    "    print(\"fork tag 만들었어\")\n",
    "    fork_tag = trainer.create_tag(project_id=project_id, name = \"fork\")\n",
    "if scissors_tag is None:\n",
    "    print(\"scissors tag 만들었어\")\n",
    "    scissors_tag = trainer.create_tag(project_id=project_id, name = \"scissors\")\n",
    "\n",
    "print(fork_tag.id, fork_tag.name)\n",
    "print(scissors_tag.id, scissors_tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c33a73ad2f66b",
   "metadata": {},
   "source": [
    "### 라벨 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81556ddac14a48e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:50:01.635985Z",
     "start_time": "2025-03-26T02:50:01.631984Z"
    }
   },
   "outputs": [],
   "source": [
    "# [x, y, width, height]\n",
    "fork_image_regions = {\n",
    "    \"fork_1\": [ 0.145833328, 0.3509314, 0.5894608, 0.238562092 ],\n",
    "    \"fork_2\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"fork_3\": [ 0.09191177, 0.0682516545, 0.757352948, 0.6143791 ],\n",
    "    \"fork_4\": [ 0.254901975, 0.185898721, 0.5232843, 0.594771266 ],\n",
    "    \"fork_5\": [ 0.2365196, 0.128709182, 0.5845588, 0.71405226 ],\n",
    "    \"fork_6\": [ 0.115196079, 0.133611143, 0.676470637, 0.6993464 ],\n",
    "    \"fork_7\": [ 0.164215669, 0.31008172, 0.767156839, 0.410130739 ],\n",
    "    \"fork_8\": [ 0.118872553, 0.318251669, 0.817401946, 0.225490168 ],\n",
    "    \"fork_9\": [ 0.18259804, 0.2136765, 0.6335784, 0.643790841 ],\n",
    "    \"fork_10\": [ 0.05269608, 0.282303959, 0.8088235, 0.452614367 ],\n",
    "    \"fork_11\": [ 0.05759804, 0.0894935, 0.9007353, 0.3251634 ],\n",
    "    \"fork_12\": [ 0.3345588, 0.07315363, 0.375, 0.9150327 ],\n",
    "    \"fork_13\": [ 0.269607842, 0.194068655, 0.4093137, 0.6732026 ],\n",
    "    \"fork_14\": [ 0.143382356, 0.218578458, 0.7977941, 0.295751631 ],\n",
    "    \"fork_15\": [ 0.19240196, 0.0633497, 0.5710784, 0.8398692 ],\n",
    "    \"fork_16\": [ 0.140931368, 0.480016381, 0.6838235, 0.240196079 ],\n",
    "    \"fork_17\": [ 0.305147052, 0.2512582, 0.4791667, 0.5408496 ],\n",
    "    \"fork_18\": [ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "    \"fork_19\": [ 0.219362751, 0.141781077, 0.5919118, 0.6683006 ],\n",
    "    \"fork_20\": [ 0.180147052, 0.239820287, 0.6887255, 0.235294119 ]\n",
    "}\n",
    "\n",
    "scissors_image_regions = {\n",
    "    \"scissors_1\": [ 0.4007353, 0.194068655, 0.259803921, 0.6617647 ],\n",
    "    \"scissors_2\": [ 0.426470578, 0.185898721, 0.172794119, 0.5539216 ],\n",
    "    \"scissors_3\": [ 0.289215684, 0.259428144, 0.403186262, 0.421568632 ],\n",
    "    \"scissors_4\": [ 0.343137264, 0.105833367, 0.332107842, 0.8055556 ],\n",
    "    \"scissors_5\": [ 0.3125, 0.09766343, 0.435049027, 0.71405226 ],\n",
    "    \"scissors_6\": [ 0.379901975, 0.24308826, 0.32107842, 0.5718954 ],\n",
    "    \"scissors_7\": [ 0.341911763, 0.20714055, 0.3137255, 0.6356209 ],\n",
    "    \"scissors_8\": [ 0.231617644, 0.08459154, 0.504901946, 0.8480392 ],\n",
    "    \"scissors_9\": [ 0.170343131, 0.332957536, 0.767156839, 0.403594762 ],\n",
    "    \"scissors_10\": [ 0.204656869, 0.120539248, 0.5245098, 0.743464053 ],\n",
    "    \"scissors_11\": [ 0.05514706, 0.159754932, 0.799019635, 0.730392158 ],\n",
    "    \"scissors_12\": [ 0.265931368, 0.169558853, 0.5061275, 0.606209159 ],\n",
    "    \"scissors_13\": [ 0.241421565, 0.184264734, 0.448529422, 0.6830065 ],\n",
    "    \"scissors_14\": [ 0.05759804, 0.05027781, 0.75, 0.882352948 ],\n",
    "    \"scissors_15\": [ 0.191176474, 0.169558853, 0.6936275, 0.6748366 ],\n",
    "    \"scissors_16\": [ 0.1004902, 0.279036, 0.6911765, 0.477124184 ],\n",
    "    \"scissors_17\": [ 0.2720588, 0.131977156, 0.4987745, 0.6911765 ],\n",
    "    \"scissors_18\": [ 0.180147052, 0.112369314, 0.6262255, 0.6666667 ],\n",
    "    \"scissors_19\": [ 0.333333343, 0.0274019931, 0.443627447, 0.852941155 ],\n",
    "    \"scissors_20\": [ 0.158088237, 0.04047389, 0.6691176, 0.843137264 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426381bfead102c7",
   "metadata": {},
   "source": [
    "### 이미지 업로드 : Labeling을 위한 구역 설정, 태그를 포함해서 이미지 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16b6ca1c7143f0d3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE LIST LENGTH: 40\n",
      "{'additional_properties': {}, 'is_batch_successful': False, 'images': [<azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2030>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2060>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B20F0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B20C0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2150>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B21E0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2270>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2300>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497CF15340>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2390>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2420>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2600>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2090>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2630>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8A5310>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B26C0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2750>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E89D550>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E89D490>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2930>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B24B0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2B10>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2960>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2B40>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2BD0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2CF0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2EA0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B2F60>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3020>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B30E0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B31A0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3260>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3320>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B33E0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B34D0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3590>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3650>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3710>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B37D0>, <azure.cognitiveservices.vision.customvision.training.models._models_py3.ImageCreateResult object at 0x000002497E8B3890>]}\n",
      "40\n",
      "scissors_8: OKDuplicate\n",
      "scissors_4: OKDuplicate\n",
      "scissors_17: OKDuplicate\n",
      "scissors_13: OKDuplicate\n",
      "scissors_9: OKDuplicate\n",
      "scissors_6: OKDuplicate\n",
      "scissors_2: OKDuplicate\n",
      "scissors_5: OKDuplicate\n",
      "scissors_20: OKDuplicate\n",
      "scissors_18: OKDuplicate\n",
      "scissors_12: OKDuplicate\n",
      "scissors_1: OKDuplicate\n",
      "scissors_10: OKDuplicate\n",
      "fork_20: OKDuplicate\n",
      "fork_13: OKDuplicate\n",
      "fork_12: OKDuplicate\n",
      "scissors_14: OKDuplicate\n",
      "scissors_11: OKDuplicate\n",
      "fork_19: OKDuplicate\n",
      "fork_11: OKDuplicate\n",
      "scissors_7: OKDuplicate\n",
      "fork_14: OKDuplicate\n",
      "fork_9: OKDuplicate\n",
      "fork_7: OKDuplicate\n",
      "fork_16: OKDuplicate\n",
      "fork_8: OKDuplicate\n",
      "fork_6: OKDuplicate\n",
      "scissors_3: OKDuplicate\n",
      "fork_5: OKDuplicate\n",
      "fork_3: OKDuplicate\n",
      "fork_18: OKDuplicate\n",
      "fork_17: OKDuplicate\n",
      "fork_15: OKDuplicate\n",
      "fork_4: OKDuplicate\n",
      "fork_2: OKDuplicate\n",
      "scissors_19: OKDuplicate\n",
      "scissors_16: OKDuplicate\n",
      "scissors_15: OKDuplicate\n",
      "fork_10: OKDuplicate\n",
      "fork_1: OKDuplicate\n"
     ]
    }
   ],
   "source": [
    "image_list = list()\n",
    "\n",
    "for file_name in fork_image_regions.keys():\n",
    "    with open(\"./fork/\" + file_name + \".jpg\", \"rb\") as image:\n",
    "        # fork_image_regions 정보를 들고 와서, x, y, width, height 좌표를 들고 와서\n",
    "        # Region 정보를 만들어준다.\n",
    "        left, top, width, height = fork_image_regions[file_name]\n",
    "        region_list = [Region(tag_id=fork_tag.id, left=left, top=top, width=width, height=height)]\n",
    "\n",
    "        # print(image)\n",
    "        image_data = image.read()\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_data, regions=region_list))\n",
    "        # image_data를 ImageFileCreateEntry를 만들어서 파일 리스트에 넣어준다.\n",
    "\n",
    "for file_name in scissors_image_regions.keys():\n",
    "    with open(\"./scissor/\" + file_name + \".jpg\", \"rb\") as image:\n",
    "        # scissors_image_regions 정보를 들고 와서, x, y, width, height 좌표를 들고 와서\n",
    "        # Region 정보를 만들어준다.\n",
    "        left, top, width, height = scissors_image_regions[file_name]\n",
    "        region_list = [Region(tag_id=scissors_tag.id, left=left, top=top, width=width, height=height)]\n",
    "\n",
    "        # print(image)\n",
    "        image_data = image.read()\n",
    "        image_list.append(ImageFileCreateEntry(name=file_name, contents=image_data, regions=region_list))\n",
    "        # image_data를 ImageFileCreateEntry를 만들어서 파일 리스트에 넣어준다.\n",
    "\n",
    "print(\"IMAGE LIST LENGTH:\", len(image_list))\n",
    "upload_result = trainer.create_images_from_files(project_id=project.id, batch=ImageFileCreateBatch(images=image_list))\n",
    "print(upload_result)\n",
    "\n",
    "print(len(image_list))\n",
    "\n",
    "if upload_result.is_batch_successful:\n",
    "    print(\"Succeeded!\")\n",
    "else:\n",
    "    for image in upload_result.images:\n",
    "        print(\"{}: {}\".format(image.source_url, image.status))\n",
    "\n",
    "# with open(\"./fork/fork_1.jpg\", \"rb\") as image:\n",
    "#     image_data = image.read()\n",
    "\n",
    "# with open(\"./scissor/scissors_1.jpg\", \"rb\") as image2:\n",
    "#     image_data2 = image2.read()\n",
    "\n",
    "# # IPython.display를 활용하여 이미지를 표시합니다.\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(data=image_data))\n",
    "# display(Image(data=image_data2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8f1b995117f09",
   "metadata": {},
   "source": [
    "### 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fdc7b0f3a05d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n",
      "Training Completed!\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "exist_iteration_list = trainer.get_iterations(project_id=project.id)\n",
    "\n",
    "if len(exist_iteration_list) > 0:\n",
    "    iteration = exist_iteration_list[0]\n",
    "else:\n",
    "    iteration = trainer.train_project(project_id=project.id)\n",
    "\n",
    "print(iteration.status)\n",
    "\n",
    "while iteration.status == \"Training\":\n",
    "    iteration = trainer.get_iteration(project_id=project.id, iteration_id=iteration.id)\n",
    "    print(\"Training Status : {}\".format(iteration.status))\n",
    "    time.sleep(5)\n",
    "print(\"Training Completed!\")\n",
    "print(iteration.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3579d64d4bc79",
   "metadata": {},
   "source": [
    "### 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26874b8738c790b",
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomVisionErrorException",
     "evalue": "Iteration is already published as: 6b021-kitchen-v1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCustomVisionErrorException\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m publish_name = \u001b[33m\"\u001b[39m\u001b[33m6b021-kitchen-v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpublish_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpublish_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_resource_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jooeu\\Desktop\\git\\ms-ai-school\\.venv\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\training\\operations\\_custom_vision_training_client_operations.py:2522\u001b[39m, in \u001b[36mCustomVisionTrainingClientOperationsMixin.publish_iteration\u001b[39m\u001b[34m(self, project_id, iteration_id, publish_name, prediction_id, overwrite, custom_headers, raw, **operation_config)\u001b[39m\n\u001b[32m   2519\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.send(request, stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **operation_config)\n\u001b[32m   2521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m200\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2522\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m models.CustomVisionErrorException(\u001b[38;5;28mself\u001b[39m._deserialize, response)\n\u001b[32m   2524\u001b[39m deserialized = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n",
      "\u001b[31mCustomVisionErrorException\u001b[39m: Iteration is already published as: 6b021-kitchen-v1"
     ]
    }
   ],
   "source": [
    "publish_name = \"6b021-kitchen-v1\"\n",
    "trainer.publish_iteration(project_id=project.id, iteration_id=iteration.id, publish_name=publish_name, prediction_id=prediction_resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70445bf8bdb0a6",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8026c2c20cd35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scissors: 93.76\n",
      "{'additional_properties': {}, 'left': 0.1630137, 'top': 0.11486101, 'width': 0.55311877, 'height': 0.71404594}\n",
      "fork: 88.05\n",
      "{'additional_properties': {}, 'left': 0.37591767, 'top': 0.42620915, 'width': 0.6240813, 'height': 0.5089747}\n",
      "scissors: 71.40\n",
      "{'additional_properties': {}, 'left': 0.28753316, 'top': 0.0, 'width': 0.6254374, 'height': 0.70839953}\n",
      "fork: 64.33\n",
      "{'additional_properties': {}, 'left': 0.25505656, 'top': 0.20537111, 'width': 0.588696, 'height': 0.7946279}\n",
      "scissors: 28.55\n",
      "{'additional_properties': {}, 'left': 0.40992343, 'top': 0.28314656, 'width': 0.58930194, 'height': 0.6553321}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./test/test_image2.jpg\", \"rb\") as image:\n",
    "    image_data = image.read()\n",
    "\n",
    "response = predictor.detect_image(project_id=project.id, published_name=publish_name, image_data=image_data)\n",
    "# response = predictor.detect_image_url(project_id=project.id, published_name=publish_name, url='https://th.bing.com/th/id/OIP.GHYEylk0GqTnHEV0H4XTpgHaEO?rs=1&pid=ImgDetMain')\n",
    "\n",
    "for prediction in response.predictions:\n",
    "    tag_name = prediction.tag_name\n",
    "    probability = prediction.probability\n",
    "    bounding_box = prediction.bounding_box\n",
    "\n",
    "    if probability > 0.1:\n",
    "        print(\"{}: {:0.2f}\".format(tag_name, probability*100))\n",
    "        print(bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f2d4a",
   "metadata": {},
   "source": [
    "### 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f38c7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomVisionErrorException",
     "evalue": "b30eb8ff-e0a1-4ef4-b695-d48f4e263347 is already queued for export",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCustomVisionErrorException\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m export = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExportPlatform\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(export)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jooeu\\anaconda3\\envs\\ms-ai\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\training\\operations\\_custom_vision_training_client_operations.py:2241\u001b[39m, in \u001b[36mCustomVisionTrainingClientOperationsMixin.export_iteration\u001b[39m\u001b[34m(self, project_id, iteration_id, platform, flavor, custom_headers, raw, **operation_config)\u001b[39m\n\u001b[32m   2238\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.send(request, stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **operation_config)\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m200\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m models.CustomVisionErrorException(\u001b[38;5;28mself\u001b[39m._deserialize, response)\n\u001b[32m   2243\u001b[39m deserialized = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n",
      "\u001b[31mCustomVisionErrorException\u001b[39m: b30eb8ff-e0a1-4ef4-b695-d48f4e263347 is already queued for export"
     ]
    }
   ],
   "source": [
    "export = trainer.export_iteration(project_id=project.id, iteration_id=iteration.id, platform=ExportPlatform.onnx)\n",
    "print(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8bbef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'platform': 'ONNX', 'status': 'Done', 'download_uri': 'https://irisprodwetraining.blob.core.windows.net:443/m-99e922e4ce8e47efb9f753b28b9471c8/b30eb8ffe0a14ef4b695d48f4e263347.ONNX.zip?skoid=385dcd54-eca6-48f6-a442-fdca98769d93&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2025-03-26T10%3A43%3A27Z&ske=2025-03-27T10%3A43%3A27Z&sks=b&skv=2021-08-06&sv=2021-08-06&spr=https&st=2025-03-26T10%3A43%3A27Z&se=2025-03-27T10%3A43%3A27Z&sr=b&sp=r&sig=%2B78dnEhyT29gqbd%2BY5RCN7SR8wR7CUv4MSH5ms6V55Y%3D', 'flavor': None, 'newer_version_available': False}\n"
     ]
    }
   ],
   "source": [
    "exports = trainer.get_exports(project_id=project.id, iteration_id=iteration.id)\n",
    "export = exports[-1]\n",
    "print(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d458e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # type: ignore\n",
    "\n",
    "response = requests.get(export.download_uri)\n",
    "with open(\"kitchen-v1.zip\", \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
